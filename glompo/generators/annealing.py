from typing import Iterable, Sequence, Tuple, Union

import numpy as np
from scipy.optimize._dual_annealing import EnergyState, ObjectiveFunWrapper, StrategyChain, VisitingDistribution

from .basegenerator import BaseGenerator
from ..common.helpers import is_bounds_valid
from ..core.manager import GloMPOManager  # TODO Remove

__all__ = ("AnnealingGenerator",)


# TODO Incorporate counter for not_improved steps?
# TODO Temperature update wrong
# TODO No points ever accepted
class AnnealingGenerator(BaseGenerator):
    """ Wrapper around the annealing core of :meth:`scipy.optimize.dual_annealing`.

    New optimizers will be started at points generated by the :func:`scipy:VisitingDistribution.visiting`. The
    incumbent results of existing optimizers will guide the 'current location' of the annealing method.

    Parameters
    ----------
    bounds
        Sequence of (min, max) pairs for each parameter in the search space.
    qa
        The accept distribution parameter.
    qv
        The visiting distribution parameter.
    seed
        Seed for the random number generator for reproducibility.
    """

    def __init__(self,
                 bounds: Sequence[Tuple[float, float]],
                 task,
                 qa: float = -5.0,
                 qv: float = 2.62,
                 initial_temperature: float = 5230,
                 seed: Union[None, int, np.ndarray, Iterable, float] = None):
        super().__init__()

        if is_bounds_valid(bounds):
            self.lb, self.ub = np.array(bounds).T

        self.rand_state = np.random.RandomState(seed)

        self.n_params = len(bounds)
        self.current_fx = float('inf')
        self.current_x = []

        self.initial_temperature = initial_temperature
        self.temperature = initial_temperature
        self.qv = qv
        self.qa = qa

        # Scipy Internals
        self.obj_wrapper = ObjectiveFunWrapper(task)
        self.visiting_dist = VisitingDistribution(self.lb, self.ub, qv, self.rand_state)
        self.state = EnergyState(self.lb, self.ub)
        self.state.reset(self.obj_wrapper, self.rand_state)
        self.chain = StrategyChain(qa, self.visiting_dist, self.obj_wrapper, None, self.rand_state, self.state)

    def generate(self, manager: 'GloMPOManager') -> np.ndarray:
        """
        EVALUATES POINTS WITHIN THE GENERATOR!!! IF USED GENERALLY WITHIN THE GLOMPO CONTEXT MAY CAUSE LOTS OF PROBLEMS

        Procedure:

           Copy the procedure from scipy almost exactly with LOCAL function evaluations and only start optimizers when a
           local searach is run.
        """
        print('---------------------')
        step = manager.o_counter - 1  # Decrease by one to match scipy counting notation
        mod_step = step % (2 * self.n_params)
        print(step + 1, step, mod_step)

        # Update temperature
        if mod_step == 0:
            t1 = np.exp((self.qv - 1) * np.log(2)) - 1
            t2 = np.exp((self.qv - 1) * np.log(step / (2 * self.n_params) + 2)) - 1
            self.temperature = self.initial_temperature * t1 / t2
            print('temperature update')
            print('   t1', t1)
            print('   t2', t2)
            print('   new temp', self.temperature)

        self.chain.run(mod_step, self.temperature)

        print('returning ', self.state.current_location)

        return self.state.current_location

    # def generate(self, manager: 'GloMPOManager') -> np.ndarray:
    #     """
    #     Procedure:
    #
    #        #. Determine current location:
    #
    #           #. If new, select random location.
    #
    #           #. If established, select best of previous optimizer and run accept_reject on it.
    #
    #        #. Update temperature with the same frequency as dual_annealing method.
    #
    #        #. Generate new point and return this as the starting point of a new optimizer.
    #     """
    #     print('---------------------')
    #     step = manager.o_counter - 1  # Decrease by one to match scipy counting notation
    #     mod_step = step % (2 * self.n_params)
    #     print(step + 1, step, mod_step)
    #
    #     # Determine current location (try get best of previous opt, otherwise choose random location)
    #     # Look backward through previous optimizers to find one with a valid return
    #     best_previous_opt = {'x': [], 'fx': float('inf')}
    #     # for i in range(step, 0, -1):
    #     #     best_previous_opt = manager.opt_log.get_best_iter(i)
    #     #     print('looking at ', i, ' it has an fx of ', best_previous_opt['fx'])
    #     #     if best_previous_opt['fx'] < float('inf'):
    #     #         print('selecting ', i)
    #     #         break
    #     best_previous_opt = manager.opt_log.get_best_iter()
    #     print(best_previous_opt)
    #     if best_previous_opt['x'] != []:
    #         if self.current_x is None or best_previous_opt['fx'] < self.current_fx:
    #             print('currents accepted')
    #             self.current_x = best_previous_opt['x']
    #             self.current_fx = best_previous_opt['fx']
    #         else:
    #             print('accept_reject previous point')
    #             self.accept_reject(best_previous_opt['x'], best_previous_opt['fx'], mod_step)
    #     else:
    #         print('returning random point')
    #         rand_x = self.lb + (self.ub - self.lb) * self.rand_state.random(self.n_params)
    #         return rand_x
    #
    #     # Update temperature
    #     # if mod_step == 0:
    #     #     t1 = np.exp((self.qv - 1) * np.log(2)) - 1
    #     #     t2 = np.exp((self.qv - 1) * np.log(step / (2 * self.n_params) + 2)) - 1
    #     #     self.temperature = self.initial_temperature * t1 / t2
    #     #     print('temperature update')
    #     #     print('   t1', t1)
    #     #     print('   t2', t2)
    #     #     print('   new temp', self.temperature)
    #     if mod_step == 0:
    #         self.temperature /= 2
    #     print('temperature update ', self.temperature)
    #
    #     # Generate new point
    #     new_x = self.visiting_dist.visiting(np.array(self.current_x), mod_step, self.temperature)
    #     print('current x: ', self.current_x)
    #     print('returning x: ', new_x)
    #     print('======================')
    #     return new_x

    def accept_reject(self, x: Sequence[float], fx: float, step):
        """
        Adapted from scipy.optimize._dual_annealing.StrategyChain.accept_reject
        """
        temp_step = self.temperature / float(step + 1)
        r = self.rand_state.random_sample()
        pqv_temp = (self.qa - 1.0) * (fx - self.current_fx) / (temp_step + 1)
        if pqv_temp <= 0.:
            pqv = 0.
        else:
            pqv = np.exp(np.log(pqv_temp) / (1. - self.qa))

        if r <= pqv:
            print('point accepted')
            self.current_x = x
            self.current_fx = fx
        else:
            print('point rejected')
