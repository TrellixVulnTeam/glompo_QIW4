""" Contains classes which save log information for GloMPO and its optimizers. """
import datetime
import warnings
from pathlib import Path
from typing import Any, Dict, List, Optional, Sequence, Union

import numpy as np
import tables as tb

from ..common.helpers import deepsizeof, glompo_colors, rolling_best
from ..common.namedtuples import IterationResult

try:
    from yaml import CDumper as Dumper
except ImportError:
    from yaml import Dumper
try:
    import matplotlib.pyplot as plt
    import matplotlib.lines as lines

    HAS_MATPLOTLIB = True
except (ModuleNotFoundError, ImportError):
    HAS_MATPLOTLIB = False

__all__ = ("OptimizerLogger",)


# noinspection PyProtectedMember
class OptimizerLogger:
    """ Stores progress of GloMPO optimizers. GloMPO logs all information into HDF5 format through PyTables.
        OptimizerLogger handles all management of the logfile and provides a simplified interface for its manipulation.
        Results of living optimizers are held in memory to optimizer hunting.
    """

    def __init__(self, path: Union[str, Path], checksum: str, n_parms: int, expected_rows: int, refresh: bool):
        """ Setups and opens the logfile.

            Parameters
            ----------
            path: Union[str, Path]
                File path in which to construct the logfile.
            checksum: str, n_parms: int
                Unique checksum value generated by GloMPOManager and stored in checkpoints and the logfile. When a
                checkpoint is loaded, GloMPO will confirm a match between the checksum value in the checkpoint and in
                the logfile before using it.
            expected_rows: int
                Estimated number of rows in each optimizer log file. Estimated by GloMPOManager based on convergence
                settings and dimensionality of the optimization task.
            refresh: bool
                If True OptimizerLogger will build a new logfile rather than load an old one.
        """
        mode = 'w' if refresh else 'a'

        self.pytab_file = tb.open_file(str(path), mode, filters=tb.Filters(1, 'blosc'))
        self.expected_rows = expected_rows
        self.n_task_dims = n_parms

        self._f_counter = 0  # Total number of evaluations accepted
        self._o_counter = 0  # Total number of optimizers started
        self._cache = Cache()
        self._chunk = {}  # Iterations are written to in chunks save time
        self._unflushed = 0
        self._est_iter_size = 0  # Estimated size of a single iteration result

        self.pytab_file.root._v_attrs.checksum = checksum
        if refresh:
            self._best_iters = {0: {'opt_id': 0, 'x': [], 'fx': float('inf')}}
            self._best_iter = {'opt_id': 0, 'x': [], 'fx': float('inf')}
            self._max_eval = -float('inf')
        else:
            self._best_iters = self.pytab_file.root._v_attrs.best_iters
            self._best_iter = self.pytab_file.root._v_attrs.best_iter
            self._max_eval = self.pytab_file.root._v_attrs.max_eval

    def __contains__(self, opt_id: int) -> bool:
        """ Returns True if a group exists in the HDF5 file for the optimizer with ID opt_id """
        return f'optimizer_{opt_id}' in self.pytab_file

    def __getitem__(self, opt_id: int) -> tb.Group:
        """ Returns an individual optimizer log. """
        return self.pytab_file.get_node('/', f'/optimizer_{opt_id}')

    def __len__(self) -> int:
        """ Returns the overall number of function evaluations stored in the log. """
        return self._f_counter

    @property
    def n_optimizers(self):
        return self._o_counter

    @property
    def _largest_eval(self):
        """ Returns the largest numerical evaluation result of the optimization funtion. """
        return self._max_eval

    def len(self, opt_id: int) -> int:
        if opt_id in self._cache:
            return len(self._cache.get_history(opt_id, 'fx'))

        group = self[opt_id]
        if 'iter_hist' in group:
            return group['iter_hist'].nrows
        return 0

    def best_iter(self, opt_id: Optional[int] = None) -> Dict[str, Any]:
        if opt_id:
            return self._best_iters[opt_id]
        return self._best_iter

    def add_optimizer(self, opt_id: int, opt_type: str, t_start: datetime.datetime):
        group = self.pytab_file.create_group(where='/',
                                             name=f'optimizer_{opt_id}')
        self.pytab_file.create_vlarray(where=f'/optimizer_{opt_id}',
                                       name='messages',
                                       atom=tb.VLUnicodeAtom(),
                                       title="Messages Generated by Optimizer",
                                       expectedrows=3)
        self._cache.add_optimizer(opt_id)
        self._chunk[opt_id] = []

        for key, val in zip(('opt_id', 'opt_type', 't_start'),
                            (opt_id, opt_type, t_start)):
            group._v_attrs[key] = val
            self._cache.put_metadata(opt_id, key, val)

        group._v_attrs.best_call_id = 0
        self._o_counter += 1
        self._best_iters[opt_id] = {'opt_id': opt_id, 'x': [], 'fx': float('inf')}

    def add_iter_history(self, opt_id: int, extra_headers: Optional[Dict[str, tb.Col]] = None):
        headers = {'call_id': tb.UInt32Col(pos=-4),
                   'iter_id': tb.UInt32Col(pos=-3),
                   'x': tb.Float64Col(shape=self.n_task_dims, pos=-2),
                   'fx': tb.Float64Col(pos=-1)}

        if extra_headers:
            headers = {**headers, **extra_headers}

        self.pytab_file.create_table(where=f'/optimizer_{opt_id}',
                                     name='iter_hist',
                                     description=headers,
                                     title="Iteration History",
                                     expectedrows=self.expected_rows)

    def put_iteration(self, iter_res: IterationResult):
        opt_id = iter_res.opt_id  # Alias
        group = self[opt_id]
        self._f_counter += 1

        if self._est_iter_size == 0:
            self._est_iter_size = deepsizeof(iter_res)

        last_iter = self.get_history(opt_id, 'iter_id')
        last_iter = last_iter[-1] if len(last_iter) > 0 else 0
        assert (iter_res.iter_id == last_iter) or (iter_res.iter_id == last_iter + 1), \
            f"Received iter {iter_res.iter_id}, iter {last_iter} in log. Iteration missing."

        if iter_res.fx < self._best_iters[opt_id]['fx']:
            self._best_iters[opt_id] = {'opt_id': opt_id, 'x': iter_res.x, 'fx': iter_res.fx}
            group._v_attrs.best_call_id = self._f_counter

            if iter_res.fx < self._best_iter['fx']:
                self._best_iter = {'opt_id': opt_id, 'x': iter_res.x, 'fx': iter_res.fx}
                self.pytab_file.root._v_attrs.best_call_id = self._f_counter

        elif iter_res.fx > self._max_eval and np.isfinite(iter_res.fx):
            self._max_eval = iter_res.fx

        self._cache.put_iteration(opt_id, self._f_counter, iter_res.iter_id, iter_res.x, iter_res.fx)
        self._chunk[opt_id].append([(self._f_counter, iter_res.iter_id, iter_res.x, iter_res.fx, *iter_res.extras)])

        if self._est_iter_size * self._unflushed > 100_000_000:  # Flush approximately every 100MB
            self.flush(opt_id)
        else:
            self._unflushed += 1

    def put_metadata(self, opt_id: int, key: str, value: str):
        """ Adds metadata about an optimizer. """
        if opt_id in self._cache:
            self._cache.put_metadata(opt_id, key, value)
        self[opt_id]._v_attrs[key] = value

    def put_message(self, opt_id: int, message: str):
        """ Optimizers can signal special messages to the optimizer during the optimization which can be saved to
            the log.
        """
        table = self[opt_id]['messages']
        table.append(message)
        table.flush()

    def get_metadata(self, opt_id, key: str) -> Any:
        """ Returns metadata of a given optimizer and key. """
        if opt_id in self._cache:
            return self._cache.get_metadata(opt_id, key)
        return self[opt_id]._v_attrs[key]

    def get_history(self, opt_id: int, track: str) -> List:
        """ Returns data from the evaluation history of optimizer opt_id.

            Parameters
            ----------
            opt_id: int
                Unique optimizer identifier.
            track: str
                Column name to return. Any column name in the logfile can be used. The following are always present:
                    - 'call_id'
                        The overall evaluation number across all function calls.
                    - 'iter_id'
                        Iteration numbers for the evaluations used by the optimizer (some population based
                        optimizers use several evaluations per algorithm iteration).
                    - 'x'
                        Input vectors evaluated by the optimizer.
                    - 'fx'
                        The function response for each iteration.
        """
        if opt_id in self._cache and track in ('call_id', 'iter_id', 'x', 'fx'):  # The cache does not hold all columns
            return self._cache.get_history(opt_id, track)

        group = self[opt_id]
        if 'iter_hist' in group:
            self.flush(opt_id)
            return group['iter_hist'].col(track)

        return []

    def plot_optimizer_trials(self, path: Optional[Path] = None, opt_id: Optional[int] = None):
        """ Generates plots for each optimizer in the log of each trialed parameter value as a function of optimizer
            iterations.
        """

        if not HAS_MATPLOTLIB:
            warnings.warn("Matplotlib not present cannot create plots.", ImportWarning)
            return

        is_interactive = plt.isinteractive()
        if is_interactive:
            plt.ioff()

        opt_ids = [opt_id] if opt_id else range(1, self.n_optimizers + 1)

        for opt in opt_ids:
            x_all = self.get_history(opt, 'x')

            fig, ax = plt.subplots(figsize=(12, 8))
            fig: plt.Figure
            ax: plt.Axes

            ax.plot(x_all)
            ax.set_xlabel('Iteration')
            ax.set_ylabel('Parameter Value')
            ax.set_title('Parameter values as a function of optimizer iteration number')

            name = f'opt{opt}_parms.png' if path is None else Path(path, f'opt{opt}_parms.png')
            fig.savefig(name)
            plt.close(fig)

        if is_interactive:
            plt.ion()

    def plot_trajectory(self, title: Union[Path, str], log_scale: bool = False, best_fx: bool = False):
        """ Generates a plot of each optimizer function values versus the overall function evaluation number.

            Parameters
            ----------
            title: Union[Path, str]
                Path to file to which the plot should be saved.
            log_scale: bool = False
                If True the function evaluations will be converted to base 10 log values.
            best_fx: bool = False
                If True the best function evaluation see thus far of each optimizer will be plotted rather than the
                function evaluation at the matching evaluation number.
        """

        if not HAS_MATPLOTLIB:
            warnings.warn("Matplotlib not present cannot create plots.", ImportWarning)
            return

        is_interactive = plt.isinteractive()
        if is_interactive:
            plt.ioff()

        fig, ax = plt.subplots(figsize=(12, 8))
        fig: plt.Figure
        ax: plt.Axes

        leg_elements = [lines.Line2D([], [], ls='-', c='black', label='Optimizer Evaluations'),
                        lines.Line2D([], [], ls='', marker='x', c='black', label='Optimizer Killed'),
                        lines.Line2D([], [], ls='', marker='s', c='black', label='Optimizer Crashed'),
                        lines.Line2D([], [], ls='', marker='*', c='black', label='Optimizer Converged')]

        colors = glompo_colors()
        y_lab = "Best Function Evaluation" if best_fx else "Function Evaluation"
        for opt_id in range(1, self.n_optimizers + 1):
            f_calls = self.get_history(opt_id, 'call_id')
            traj = self.get_history(opt_id, 'fx')
            if best_fx:
                traj = rolling_best(traj)

            if log_scale:
                traj = np.sign(traj) * np.log10(np.abs(traj))
                stub = "fx_best" if best_fx else "fx"
                y_lab = f"sign({stub}) * log10(|{stub}|)"

            ax.plot(f_calls, traj, ls='-', marker='.', c=colors(opt_id))
            leg_elements.append(lines.Line2D([], [], ls='-', c=colors(opt_id),
                                             label=f"{opt_id}: {self.get_metadata(opt_id, 'opt_type')}"))

            try:
                end_cond = self.get_metadata(opt_id, "end_cond")
                if "GloMPO Termination" in end_cond:
                    marker = 'x'
                elif "Optimizer convergence" in end_cond or "Normal termination" in end_cond:
                    marker = '*'
                elif "Error termination" in end_cond or "Traceback" in end_cond:
                    marker = 's'
                else:
                    marker = ''
                ax.plot(f_calls[-1], traj[-1], marker=marker, color='black')
            except (KeyError, IndexError):
                pass

        ax.set_xlabel('Function Calls')
        ax.set_ylabel(y_lab)
        ax.set_title("Optimizer function evaluations over time as a function of cumulative function calls.")

        # Apply Legend
        ax.legend(loc='upper right', handles=leg_elements, bbox_to_anchor=(1.35, 1))
        box = ax.get_position()
        ax.set_position([0.85 * box.x0, box.y0, 0.85 * box.width, box.height])

        fig.savefig(title)
        plt.close(fig)

        if is_interactive:
            plt.ion()

    def flush(self, opt_id: Optional[int] = None):
        opt_ids = [opt_id] if opt_id else self._chunk.keys()

        for opt in opt_ids:
            if opt not in self._chunk:
                continue

            table = self.pytab_file.get_node(f'/optimizer_{opt}/iter_hist')
            table.append(self._chunk[opt])
            self._chunk[opt] = []
            self._unflushed = 0
            table.flush()

    def clear_cache(self, opt_id: Optional[int] = None):
        self.flush(opt_id)
        del self._chunk[opt_id]
        self._cache.clear_cache(opt_id)

    def close(self):
        self.pytab_file.root._v_attrs.opts_started = self._o_counter
        self.pytab_file.root._v_attrs.f_counter = self._f_counter
        self.pytab_file.root._v_attrs.best_iters = self._best_iters
        self.pytab_file.root._v_attrs.best_iter = self._best_iter
        self.pytab_file.root._v_attrs.max_eval = self._max_eval

        self._cache.clear_cache()

        self.flush()
        self.pytab_file.flush()
        self.pytab_file.close()


class Cache:
    """ Holds iteration results in memory for faster access """

    def __init__(self):
        self._storage = {}

    def __contains__(self, item):
        return item in self._storage

    def add_optimizer(self, opt_id: int):
        self._storage[opt_id] = {'metadata': {},
                                 'call_id': [],
                                 'iter_id': [],
                                 'x': [],
                                 'fx': []}

    def clear_cache(self, opt_id: Optional[int] = None):
        to_del = [opt_id] if opt_id else [*self._storage.keys()]
        for key in to_del:
            del self._storage[key]

    def put_metadata(self, opt_id: int, key: str, value: Any):
        self._storage[opt_id]['metadata'][key] = value

    def put_iteration(self, opt_id: int, call_id: int, iter_id: int, x: Sequence[float], fx: float):
        self._storage[opt_id]['call_id'].append(call_id)
        self._storage[opt_id]['iter_id'].append(iter_id)
        self._storage[opt_id]['x'].append(x)
        self._storage[opt_id]['fx'].append(fx)

    def get_history(self, opt_id: int, track: str) -> List:
        return self._storage[opt_id][track]

    def get_metadata(self, opt_id: int, key: str) -> Any:
        return self._storage[opt_id]['metadata'][key]
